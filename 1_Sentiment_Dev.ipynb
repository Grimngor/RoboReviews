{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' !pip install numpy\\n!pip install pandas\\n#!pip install polars\\n!pip install matplotlib\\n!pip install seaborn\\n!pip install datasets\\n!pip install transformers\\n!pip install protobuf\\n!pip install scikit-learn\\n!pip install nltk\\n!pip install evaluate '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" !pip install numpy\n",
    "!pip install pandas\n",
    "#!pip install polars\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install protobuf\n",
    "!pip install scikit-learn\n",
    "!pip install nltk\n",
    "!pip install evaluate \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import pipeline, AutoTokenizer, Trainer, TrainingArguments, AutoModelForSequenceClassification, DataCollatorWithPadding, EarlyStoppingCallback, get_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import evaluate\n",
    "import textwrap\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv('final_dataset_100k.csv')\n",
    "\n",
    "# Combine title and text columns into a single review column to provide more context\n",
    "final_df['review'] = final_df['title'].fillna('') + '. ' + final_df['text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tqdm.pandas()\n",
    "model_name = \"distilbert/distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum review length: 38\n",
      "Median review length: 93\n",
      "Mean review length: 126\n",
      "Maximum review length: 3615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze the distribution of review lengths\n",
    "final_df['review_length'] = final_df['review'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Minimum review length: {final_df['review_length'].min()}\")\n",
    "print(f\"Median review length: {int(final_df['review_length'].median())}\")\n",
    "print(f\"Mean review length: {int(final_df['review_length'].mean())}\")\n",
    "print(f\"Maximum review length: {final_df['review_length'].max()}\")\n",
    "\n",
    "# Plotting the distribution of review lengths\n",
    "sns.histplot(final_df['review_length'], bins=80)\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Review Lengths')\n",
    "plt.xlim(0, 600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing Reviews: 100%|██████████| 97115/97115 [00:34<00:00, 2818.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Implement sliding window tokenization for reviews longer than 512 tokens\n",
    "def sliding_window_tokenizer(text, max_length=400, stride=100):\n",
    "    return tokenizer(text, truncation=True, max_length=max_length, stride=stride, return_overflowing_tokens=True)\n",
    "\n",
    "# Apply sliding window tokenization to reviews\n",
    "sliding_tokenized_reviews = []\n",
    "for review in tqdm(final_df['review'], desc=\"Tokenizing Reviews\"):\n",
    "    tokenized_chunks = sliding_window_tokenizer(review)\n",
    "    sliding_tokenized_reviews.extend(tokenized_chunks['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Initialize VADER sentiment analyzer\\nnltk.download('vader_lexicon')\\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\\nanalyzer = SentimentIntensityAnalyzer()\\n\\n# Define a function to classify sentiment based on VADER scores\\ndef vader_sentiment(text):\\n    score = analyzer.polarity_scores(text)['compound']\\n    if score >= 0.33:\\n        return 'POSITIVE', score\\n    elif score <= -0.33:\\n        return 'NEGATIVE', score\\n    else:\\n        return 'NEUTRAL', score\\n\\n# Apply VADER sentiment analysis on the 'review' column\\nfinal_df[['sentiment', 'sentiment_score']] = final_df['review'].apply(\\n    lambda x: pd.Series(vader_sentiment(x))) \""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Initialize VADER sentiment analyzer\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to classify sentiment based on VADER scores\n",
    "def vader_sentiment(text):\n",
    "    score = analyzer.polarity_scores(text)['compound']\n",
    "    if score >= 0.33:\n",
    "        return 'POSITIVE', score\n",
    "    elif score <= -0.33:\n",
    "        return 'NEGATIVE', score\n",
    "    else:\n",
    "        return 'NEUTRAL', score\n",
    "\n",
    "# Apply VADER sentiment analysis on the 'review' column\n",
    "final_df[['sentiment', 'sentiment_score']] = final_df['review'].apply(\n",
    "    lambda x: pd.Series(vader_sentiment(x))) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" from matplotlib.colors import LinearSegmentedColormap\\n# Visualize the distribution of VADER sentiment predictions crossed with product ratings\\n\\ncross_tab = pd.crosstab(final_df['sentiment'], final_df['rating'])\\ncustom_cmap = LinearSegmentedColormap.from_list('red_to_green', ['red', '#f3c200', 'green'])\\ncross_tab.plot(kind='bar', stacked=True, colormap=custom_cmap)\\nplt.xlabel('VADER Sentiment')\\nplt.ylabel('Count')\\nplt.title('VADER Sentiment Predictions vs Product Ratings')\\nplt.show() \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from matplotlib.colors import LinearSegmentedColormap\n",
    "# Visualize the distribution of VADER sentiment predictions crossed with product ratings\n",
    "\n",
    "cross_tab = pd.crosstab(final_df['sentiment'], final_df['rating'])\n",
    "custom_cmap = LinearSegmentedColormap.from_list('red_to_green', ['red', '#f3c200', 'green'])\n",
    "cross_tab.plot(kind='bar', stacked=True, colormap=custom_cmap)\n",
    "plt.xlabel('VADER Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.title('VADER Sentiment Predictions vs Product Ratings')\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/97115 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 97115/97115 [07:12<00:00, 224.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer with max length for consistency\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "\n",
    "# Load the DistilRoBERTa model for sentiment analysis\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model_name, tokenizer=tokenizer, device=0)\n",
    "\n",
    "# Apply DistilRoBERTa sentiment analysis on the 'review' column with progress tracking\n",
    "def transformer_sentiment(text):\n",
    "    # Use consistent max_length and padding to prevent size mismatches\n",
    "    result = classifier(text, truncation=True, padding=True, max_length=512)[0]\n",
    "    return result['label'], result['score']\n",
    "\n",
    "# Apply the new sentiment function with progress tracking\n",
    "final_df[['sentiment', 'sentiment_score']] = final_df['review'].progress_apply(lambda x: pd.Series(transformer_sentiment(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Cross-tabulate sentiment with product ratings to visualize the alignment\n",
    "cross_tab = pd.crosstab(final_df['sentiment'], final_df['rating'])\n",
    "custom_cmap = LinearSegmentedColormap.from_list('red_to_green', ['red', '#f3c200', 'green'])\n",
    "cross_tab.plot(kind='bar', stacked=True, colormap=custom_cmap)\n",
    "plt.xlabel('Sentiment Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentiment Label Distribution Crossed with Product Ratings (DistilRoBERTa)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns and drop null rows\n",
    "final_df = final_df[['title', 'text', 'review', 'rating', 'sentiment', 'sentiment_score', 'id', 'name', 'categories', 'review_length']]\n",
    "final_df.dropna(inplace=True, axis=0)\n",
    "\n",
    "# Save the processed dataset\n",
    "final_df.to_pickle('final_dataset_sent.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df = pd.read_pickle('final_dataset_sent.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Split into train, validation, and test sets with stratification\u001b[39;00m\n\u001b[1;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m final_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m---> 10\u001b[0m train_val_df, test_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m train_df, val_df \u001b[38;5;241m=\u001b[39m train_test_split(train_val_df, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mtrain_val_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m], random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Convert splits to HuggingFace datasets\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:2638\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2634\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[1;32m   2636\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m-> 2638\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2641\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m   2642\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2643\u001b[0m     )\n\u001b[1;32m   2644\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:2197\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   2165\u001b[0m \n\u001b[1;32m   2166\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2195\u001b[0m \u001b[38;5;124;03m    to an integer.\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2197\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "# Map sentiment to labels\n",
    "label_mapping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}\n",
    "final_df['labels'] = final_df['sentiment'].map(label_mapping)\n",
    "\n",
    "# Convert to Dataset\n",
    "dataset = Dataset.from_pandas(final_df[['review', 'labels']])\n",
    "\n",
    "# Split into train, validation, and test sets with stratification\n",
    "df = final_df[['review', 'labels']]\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2, stratify=df['labels'], random_state=42)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.25, stratify=train_val_df['labels'], random_state=42)\n",
    "\n",
    "# Convert splits to HuggingFace datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa60ab0b09e461987b78cd585b83164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/94265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60667a25c126455e8ae11807440de7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31422 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ea34b90bc24ef5a374321795da7f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31422 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"review\"], truncation=True, max_length=256)\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True).remove_columns(['review'])\n",
    "tokenized_val = val_dataset.map(preprocess_function, batched=True).remove_columns(['review'])\n",
    "tokenized_test = test_dataset.map(preprocess_function, batched=True).remove_columns(['review'])\n",
    "\n",
    "\n",
    "# Define a dict mapping label IDs to their corresponding label names and viceversa\n",
    "id2label = {0: \"NEGATIVE\", 1: \"NEUTRAL\", 2: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"NEUTRAL\": 1, \"POSITIVE\": 2}\n",
    "\n",
    "# Model setup\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3, id2label=id2label, label2id=label2id)\n",
    "\n",
    "# Using dynamic padding since our sequences have variable lengths and it's more memory efficient\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary metrics\n",
    "#metrics = evaluate.load(\"accuracy\",\"f1_score\",\"precision\",\"recall\")\n",
    "metrics = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Compute metrics\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metrics.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Calculate class weights using sklearn's compute_class_weight\n",
    "claslabels = [0, 1, 2]  #  classes for NEGATIVE, NEUTRAL, POSITIVE\n",
    "weights = compute_class_weight(class_weight='balanced', classes=claslabels, y=final_df['labels'].values)\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32, device='cuda')  # Changed dtype to float32\n",
    "\n",
    "# Custom Trainer class to override the loss computation\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        global weights_tensor\n",
    "        labels = inputs.get(\"labels\")\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs.logits, labels, weight=weights_tensor)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3316' max='7360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3316/7360 30:45 < 37:31, 1.80 it/s, Epoch 8/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.507100</td>\n",
       "      <td>0.466671</td>\n",
       "      <td>0.821113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.249100</td>\n",
       "      <td>0.232423</td>\n",
       "      <td>0.928140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.167100</td>\n",
       "      <td>0.215747</td>\n",
       "      <td>0.931417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.214208</td>\n",
       "      <td>0.935364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>0.227629</td>\n",
       "      <td>0.934504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3316, training_loss=0.23642313692480577, metrics={'train_runtime': 1846.4932, 'train_samples_per_second': 1021.016, 'train_steps_per_second': 3.986, 'total_flos': 5.619267910317312e+16, 'train_loss': 0.23642313692480577, 'epoch': 9.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    report_to=['none'],\n",
    "    logging_first_step=True,\n",
    "    dataloader_num_workers=8,\n",
    "    fp16=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    "    load_best_model_at_end=True,\n",
    "    disable_tqdm=False,\n",
    ")\n",
    "\n",
    "# Initialize learning rate scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=training_args.learning_rate)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=training_args.num_train_epochs * len(tokenized_train)\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    optimizers=(optimizer, lr_scheduler)\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20697860419750214,\n",
       " 'eval_accuracy': 0.9334860925466234,\n",
       " 'eval_runtime': 20.2522,\n",
       " 'eval_samples_per_second': 1551.539,\n",
       " 'eval_steps_per_second': 12.147,\n",
       " 'epoch': 9.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./sentiment-fine-tuned-distilroberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = AutoModelForSequenceClassification.from_pretrained('./sentiment-fine-tuned-distilroberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'compute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment-analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./sentiment-fine-tuned-distilroberta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set and calculate additional metrics\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m predictions, labels, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m logits \u001b[38;5;241m=\u001b[39m predictions  \u001b[38;5;66;03m# The predictions variable contains the logits\u001b[39;00m\n\u001b[1;32m      7\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:3087\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3084\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3086\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3087\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   3089\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3090\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:3304\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3300\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3301\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   3302\u001b[0m         )\n\u001b[1;32m   3303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3304\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3306\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_preds)\u001b[0m\n\u001b[1;32m      7\u001b[0m logits, labels \u001b[38;5;241m=\u001b[39m eval_preds\n\u001b[1;32m      8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m(predictions\u001b[38;5;241m=\u001b[39mpredictions, references\u001b[38;5;241m=\u001b[39mlabels)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'compute'"
     ]
    }
   ],
   "source": [
    "# Load classifier for predictions\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"./sentiment-fine-tuned-distilroberta\")\n",
    "\n",
    "# Evaluate the model on the test set and calculate additional metrics\n",
    "predictions, labels, metrics = trainer.predict(tokenized_test)\n",
    "logits = predictions  # The predictions variable contains the logits\n",
    "predicted_labels = np.argmax(logits, axis=-1)\n",
    "\n",
    "# Calculate classification report\n",
    "print(classification_report(labels, predicted_labels, target_names=['NEGATIVE', 'NEUTRAL', 'POSITIVE']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(labels, predicted_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['NEGATIVE', 'NEUTRAL', 'POSITIVE'])\n",
    "disp.plot(cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "with open('Sentiment_Predictions.txt', 'w') as f:\n",
    "    # Print and classify a few sampled texts\n",
    "    sampled_texts = test_dataset.shuffle().select(range(5))['review']\n",
    "    for text in sampled_texts:\n",
    "        print(textwrap.fill(f\"TEXT: {text}\", width=80), file=f)\n",
    "        print(f\"CLASSIFICATION: {classifier(text)}\\n\", file=f)\n",
    "        print('-'*80, file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
